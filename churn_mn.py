# -*- coding: utf-8 -*-
"""Churn.MN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/182ciB3BAZoIdm9RAVsyhx2IZOxn_-kUj

Dataset link: https://www.kaggle.com/datasets/muhammadshahidazeem/customer-churn-dataset/code

# Churn Prediction

This dataset contains 64,374 customer records for evaluating churn prediction models. It includes the same features (like age, tenure, usage, etc.) as the training data, but without churn labels. This allows businesses to:

Test model performance: See how well the trained model predicts churn on unseen data.
Assess generalizability: Understand if the model can accurately predict churn for new customers.
Optimize retention efforts: Use the model's performance to refine strategies for keeping customers.
By analyzing this testing data, businesses can gain valuable insights into the effectiveness of their churn prediction models and improve customer retention efforts.
"""

# imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from warnings import filterwarnings
filterwarnings('ignore')

!pip install optuna
import optuna
from sklearn.model_selection import cross_validate

import sklearn

!pip install category_encoders
import category_encoders
from sklearn import set_config
from sklearn.model_selection import KFold, RandomizedSearchCV, GridSearchCV, train_test_split
import pickle
set_config(transform_output = "pandas")

import optuna.logging
optuna.logging.set_verbosity(optuna.logging.WARNING)
import os

df_test = pd.read_csv('/content/drive/MyDrive/WebSocial-24/customer_churn_dataset-testing-master.csv')

df_test.head()

df_train = pd.read_csv('/content/drive/MyDrive/WebSocial-24/customer_churn_dataset-training-master.csv')

df_train.head()

df_train.info()

df_train.describe(include='all')

"""The data shows a trend of male customers with an average age around 54. Interestingly, these customers tend to use the shop frequently, though some do experience payment delays. The most popular subscription type is Premium, and annual contracts seem to be the preferred option.  On average, customers spend more than the typical amount."""

# checking for missing values
df_train.isna().sum()

# checking for duplicates
df_train.duplicated().sum()

# check whether every customer has only one row of data
df_train['CustomerID'].value_counts().head(10)

# since customer id is unique for each row, we can drop it
df_train = df_train.drop(columns=['CustomerID']).copy()
df_train = df_train.dropna().copy()
df_test = df_test.drop(columns=['CustomerID']).copy()
df_test = df_test.dropna().copy()

# defining categorical and numeric columns
categorical_cols = df_train.select_dtypes(include='object').columns.to_list()
numeric_cols = df_train.select_dtypes(include='number').columns.to_list()

# checking for unique values in categorical columns
for col in categorical_cols:
    print(f'{col}')
    print(f'No. of unique: {df_train[col].nunique()}')
    print(f'Top 10 unique values: {df_train[col].unique()[:10]}')
    print("="*15)

# checking label balance in the dataset
df_train['Churn'].value_counts(normalize=True)

# plotting categorical variables against the target variable
import seaborn as sns
import matplotlib.pyplot as plt

fig, axes = plt.subplots(len(categorical_cols)//2+len(categorical_cols)%2, 2, figsize=(12, 6 * (len(categorical_cols)//2)))

palette = sns.color_palette('Set2')
for i, col in enumerate(categorical_cols):
    sns.countplot(x=col, data=df_train, hue='Churn', ax=axes[i//2, i%2], palette= palette)
    axes[i//2, i%2].set_xlabel(col)
    axes[i//2, i%2].set_ylabel('Count')
    axes[i//2, i%2].legend(title='Churn')

plt.tight_layout()
plt.show()

# plotting numeric variables against the target variable
fig, axes = plt.subplots(len(numeric_cols), 2, figsize=(12, 3 * len(numeric_cols)))
for i, col in enumerate(numeric_cols):
    # Histogram with KDE
    palette = sns.color_palette('Set3')
    sns.histplot(data=df_train, x=col, kde=True, hue='Churn', ax=axes[i, 0], palette= palette)
    axes[i, 0].set_title(f'{col} Histogram')
    axes[i, 0].set_xlabel(col)
    axes[i, 0].set_ylabel('Density')

    # Box Plot
    sns.boxplot(data=df_train, x=col, hue='Churn', ax=axes[i, 1], palette= palette)
    axes[i, 1].set_title(f'{col} Box Plot')
    axes[i, 1].set_xlabel(col)

plt.tight_layout()
plt.show()

"""The customer age distribution is interesting. While it leans slightly towards younger customers, there's a significant number in the 40-50 age range and a smaller but still substantial group in their 20s and 30s. It's worth noting that churn rate is particularly high for the 20-30 age group, then drops until the 41-50 age group. Surprisingly, the data shows that churn rates are very high for customers over 60.

The data reveals no significant difference in the proportion of customers across subscription types (monthly, quarterly, annual). However, churn rates paint a different picture. While nearly half of customers with annual and quarterly contracts churn, a starker trend emerges for monthly subscriptions - all customers with monthly contracts churn. This suggests a potential need to re-evaluate the value proposition or pricing for monthly plans to improve customer retention.
"""

# checking for drift in the train and test data (whether the distribution of train and test data is different)
fig, axes = plt.subplots(len(numeric_cols), 2, figsize=(12, 3 * len(numeric_cols)))
df_train['flag'] = 'Train'
df_test['flag'] = 'Test'
merged_data = pd.concat([df_train, df_test], axis=0, ignore_index=True)
for i, col in enumerate(numeric_cols):
    # Histogram with KDE, Churn=0
    sns.boxplot(data=merged_data.loc[merged_data['Churn']==0], hue='flag', x=col, ax=axes[i, 0], color='blue')
    sns.boxplot(data=merged_data.loc[merged_data['Churn']==0], hue='flag', x=col, ax=axes[i, 0], color='green')
    axes[i, 0].set_title(f'{col} Histogram: Churn=0')
    axes[i, 0].set_xlabel(col)
    axes[i, 0].set_ylabel('Density')

    # Histogram with KDE, Churn=1
    sns.boxplot(data=merged_data.loc[merged_data['Churn']==1], hue='flag', x=col, ax=axes[i, 1], color='blue')
    sns.boxplot(data=merged_data.loc[merged_data['Churn']==1], hue='flag', x=col, ax=axes[i, 1], color='green')
    axes[i, 1].set_title(f'{col} Histogram: Churn=1')
    axes[i, 1].set_xlabel(col)
    axes[i, 1].set_ylabel('Density')

plt.tight_layout()
plt.legend()
plt.show()

df_train = df_train.drop(columns=['flag'])
df_test = df_test.drop(columns=['flag'])

# creating the train and test datasets from merged data
import pandas as pd
from sklearn.model_selection import train_test_split # Import the necessary function

df_raw = pd.concat([df_train, df_test], axis=0, ignore_index=True)
df_train, df_test = train_test_split(df_raw, test_size=0.2, random_state=42, stratify=df_raw['Churn']) # Use the correct function name

# separating x and y variables
xtrain = df_train.drop(columns=['Churn']).copy()
ytrain = df_train[['Churn']].copy()
xtest = df_test.drop(columns=['Churn']).copy()
ytest = df_test[['Churn']].copy()

# splitting the data
xtrain, xval, ytrain, yval = train_test_split(xtrain, ytrain, test_size=0.3, random_state=42, stratify=ytrain)

# saving the datasets as pickle files for later use
if not os.path.exists('data/cleaned'):
    os.makedirs('/kaggle/working/churn-prediction/data/cleaned', exist_ok=True)
with open('/kaggle/working/churn-prediction/data/xtrain.pkl','wb') as f:
    pickle.dump(xtrain, f)
with open('/kaggle/working/churn-prediction/data/ytrain.pkl','wb') as f:
    pickle.dump(ytrain, f)
with open('/kaggle/working/churn-prediction/data/xtest.pkl','wb') as f:
    pickle.dump(xtest, f)
with open('/kaggle/working/churn-prediction/data/ytest.pkl','wb') as f:
    pickle.dump(ytest, f)
with open('/kaggle/working/churn-prediction/data/xval.pkl','wb') as f:
    pickle.dump(xval, f)
with open('/kaggle/working/churn-prediction/data/yval.pkl','wb') as f:
    pickle.dump(yval, f)

# encoding the categorical variables
encoder = category_encoders.TargetEncoder().fit(xtrain, ytrain)
xtrain = encoder.transform(xtrain)
xtest = encoder.transform(xtest)
xval = encoder.transform(xval)

# scaling the data
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler().fit(xtrain)
xtrain = scaler.transform(xtrain)
xtest = scaler.transform(xtest)
xval = scaler.transform(xval)

# defining some utility functions
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, log_loss

# dataframe to store model performance metrics
model_performance = pd.DataFrame(columns=['model_name', 'train_accuracy', 'test_accuracy', 'train_precision', 'test_precision',
                                          'train_recall', 'test_recall', 'train_f1', 'test_f1', 'train_roc_auc', 'test_roc_auc',
                                          'train_log_loss', 'test_log_loss'])
# dictionary to store the models
estimators = {}

# function to calculate model performance metrics
def model_scorer(clf, x, y, prefix=''):
    ypred = clf.predict(x)
    yprob = clf.predict_proba(x)[:, 1]
    score_dict = {
        prefix+'accuracy': np.round(accuracy_score(y, ypred),3),
        prefix+'precision': np.round(precision_score(y, ypred),3),
        prefix+'recall': np.round(recall_score(y, ypred),3),
        prefix+'f1': np.round(f1_score(y, ypred),3),
        prefix+'roc_auc': np.round(roc_auc_score(y, yprob),3),
        prefix+'log_loss': np.round(log_loss(y, yprob),3)
    }
    return score_dict

# function to add model performance to the dataframe and model to the dictionary
def add_model_performance(model_name, clf, xtrain=xtrain, ytrain=ytrain, xtest=xtest, ytest=ytest, df=model_performance, model_dict=estimators):
    train_scores = model_scorer(clf, xtrain, ytrain, prefix='train_')
    test_scores = model_scorer(clf, xtest, ytest, prefix='test_')
    train_scores.update(test_scores)
    train_scores['model_name'] = model_name
    df.loc[df.shape[0]] = train_scores
    model_dict[model_name] = clf
    return df,model_dict

from sklearn.linear_model import LogisticRegression

# defining the objective function for the optimization
def objective(trial, xtrain, ytrain, kf):
    params = {
        'C': trial.suggest_loguniform('C', 1e-3, 1e3),
        'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),
        'solver': trial.suggest_categorical('solver', ['liblinear'])
    }
    model = LogisticRegression(**params)
    scores = cross_validate(model, xtrain, ytrain, cv=kf, scoring='neg_log_loss', n_jobs=-1)
    loss = -scores['test_score'].mean()
    return loss

# optimization using kfold cross validation
kf = KFold(n_splits=3, shuffle=True, random_state=42)
obj_func = lambda trial: objective(trial, xtrain.values, ytrain.values.ravel(), kf)
study = optuna.create_study(direction='minimize')
study.optimize(obj_func, n_trials=30)

# printing the best score and best parameters
print(f"Best score: {study.best_value:5f}")
print(f"Best params: {study.best_params}")

# training the model with the best parameters
best_model = LogisticRegression(**study.best_params).fit(xtrain.values, ytrain.values.ravel())

# adding the model performance to the dataframe and model to the dictionary
model_performance, estimators = add_model_performance(model_name='LogisticRegression', clf=best_model)

# displaying the model performance
display(model_performance)

from sklearn.tree import DecisionTreeClassifier

def objective(trial, xtrain, ytrain, kf):
    params = {
        'max_depth': trial.suggest_int('max_depth', 1, 300, 7),
        'min_samples_split': trial.suggest_int('min_samples_split', 50, 1000, 50),
        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 50, 1000, 50),
    }
    model = DecisionTreeClassifier(**params)
    scores = cross_validate(model, xtrain, ytrain, cv=kf, scoring='neg_log_loss', n_jobs=-1)
    loss = -scores['test_score'].mean()
    return loss

kf = KFold(n_splits=3, shuffle=True, random_state=42)
obj_func = lambda trial: objective(trial, xtrain.values, ytrain.values.ravel(), kf)
study = optuna.create_study(direction='minimize',)
study.optimize(obj_func, n_trials=50)

print(f"Best score: {study.best_value:5f}")
print(f"Best params: {study.best_params}")

best_model = DecisionTreeClassifier(**study.best_params).fit(xtrain.values, ytrain.values.ravel())
model_performance, estimators = add_model_performance(model_name='DecisionTreeClassifier', clf=best_model)

display(model_performance)